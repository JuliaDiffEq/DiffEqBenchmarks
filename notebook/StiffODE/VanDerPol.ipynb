{
  "cells": [
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using OrdinaryDiffEq, DiffEqDevTools, Sundials, ParameterizedFunctions, Plots, ODE, ODEInterfaceDiffEq, ODEInterface, LSODA\ngr()\nusing LinearAlgebra\nLinearAlgebra.BLAS.set_num_threads(1)\n\nvan = @ode_def begin\n  dy = μ*((1-x^2)*y - x)\n  dx = 1*y\nend μ\n\nprob = ODEProblem(van,[0;2.],(0.0,6.3),1e6)\nabstols = 1.0 ./ 10.0 .^ (5:9)\nreltols = 1.0 ./ 10.0 .^ (2:6)\n\nsol = solve(prob,CVODE_BDF(),abstol=1/10^14,reltol=1/10^14)\ntest_sol = TestSolution(sol)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Test"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(sol,ylim=[-4;4])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(sol)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Omissions And Tweaking\n\nThe following were omitted from the tests due to convergence failures. ODE.jl's\nadaptivity is not able to stabilize its algorithms, while\nGeometricIntegratorsDiffEq has not upgraded to Julia 1.0.\nGeometricIntegrators.jl's methods used to be either fail to converge at\ncomparable dts (or on some computers errors due to type conversions)."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "#sol = solve(prob,ode23s()); println(\"Total ODE.jl steps: $(length(sol))\")\n#using GeometricIntegratorsDiffEq\n#try\n#    sol = solve(prob,GIRadIIA3(),dt=1/1000)\n#catch e\n#    println(e)\n#end"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "`ARKODE` needs a lower `nonlinear_convergence_coefficient` in order to not diverge."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sol = solve(prob,ARKODE(),abstol=1e-4,reltol=1e-2);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sol = solve(prob,ARKODE(nonlinear_convergence_coefficient = 1e-6),abstol=1e-4,reltol=1e-1);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sol = solve(prob,ARKODE(order=3),abstol=1e-4,reltol=1e-1);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sol = solve(prob,ARKODE(nonlinear_convergence_coefficient = 1e-6,order=3),abstol=1e-4,reltol=1e-1);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sol = solve(prob,ARKODE(order=5,nonlinear_convergence_coefficient = 1e-3),abstol=1e-4,reltol=1e-1);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sol = solve(prob,ARKODE(order=5,nonlinear_convergence_coefficient = 1e-4),abstol=1e-4,reltol=1e-1);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, the ROCK methods do not perform well on this benchmark."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "setups = [\n          #Dict(:alg=>ROCK2())    #Unstable\n          #Dict(:alg=>ROCK4())    #needs more iterations\n          #Dict(:alg=>ESERK5()),\n          ]"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some of the bad Rosenbrocks fail:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "setups = [\n  #Dict(:alg=>Hairer4()),\n  #Dict(:alg=>Hairer42()),\n  #Dict(:alg=>Cash4()),\n]"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The EPIRK and exponential methods also fail:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sol = solve(prob,EXPRB53s3(),dt=2.0^(-8));\nsol = solve(prob,EPIRK4s3B(),dt=2.0^(-8));\nsol = solve(prob,EPIRK5P2(),dt=2.0^(-8));"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Low Order and High Tolerance\n\nThis tests the case where accuracy is not needed as much and quick robust solutions are necessary. Note that `ARKODE`'s convergence coefficient must be lowered to `1e-7` in order to converge.\n\n#### Final timepoint error\n\nThis measures the efficiency to get the value at the endpoint correct."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "abstols = 1.0 ./ 10.0 .^ (4:7)\nreltols = 1.0 ./ 10.0 .^ (1:4)\n\nsetups = [Dict(:alg=>Rosenbrock23()),\n          Dict(:alg=>CVODE_BDF()),\n          Dict(:alg=>TRBDF2()),\n          Dict(:alg=>ddebdf()),\n          Dict(:alg=>rodas()),\n          Dict(:alg=>lsoda()),\n          Dict(:alg=>radau())]\nwp = WorkPrecisionSet(prob,abstols,reltols,setups;\n                      save_everystep=false,appxsol=test_sol,maxiters=Int(1e5),seconds=5)\nplot(wp)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "setups = [Dict(:alg=>Rosenbrock23()),\n          Dict(:alg=>Rodas3()),\n          Dict(:alg=>TRBDF2()),\n          Dict(:alg=>rodas()),\n          Dict(:alg=>lsoda()),\n          Dict(:alg=>radau()),\n          Dict(:alg=>RadauIIA5()),\n          Dict(:alg=>ROS34PW1a()),\n          ]\ngr()\nwp = WorkPrecisionSet(prob,abstols,reltols,setups;\n                      save_everystep=false,appxsol=test_sol,maxiters=Int(1e5),numruns=10)\nplot(wp)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "setups = [Dict(:alg=>Rosenbrock23()),\n          Dict(:alg=>Kvaerno3()),\n          Dict(:alg=>KenCarp4()),\n          Dict(:alg=>TRBDF2()),\n          Dict(:alg=>KenCarp3()),\n          Dict(:alg=>ARKODE(nonlinear_convergence_coefficient = 1e-6)),\n          Dict(:alg=>SDIRK2()),\n          Dict(:alg=>radau())]\nnames = [\"Rosenbrock23\" \"Kvaerno3\" \"KenCarp4\" \"TRBDF2\" \"KenCarp3\" \"ARKODE\" \"SDIRK2\" \"radau\"]\nwp = WorkPrecisionSet(prob,abstols,reltols,setups;\n                      names=names,save_everystep=false,appxsol=test_sol,maxiters=Int(1e5),seconds=5)\nplot(wp)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "setups = [Dict(:alg=>Rosenbrock23()),\n          Dict(:alg=>KenCarp5()),\n          Dict(:alg=>KenCarp4()),\n          Dict(:alg=>KenCarp3()),\n          Dict(:alg=>ARKODE(order=5,nonlinear_convergence_coefficient = 1e-4)),\n          Dict(:alg=>ARKODE(nonlinear_convergence_coefficient = 1e-6)),\n          Dict(:alg=>ARKODE(nonlinear_convergence_coefficient = 1e-6,order=3))]\nnames = [\"Rosenbrock23\" \"KenCarp5\" \"KenCarp4\" \"KenCarp3\" \"ARKODE5\" \"ARKODE4\" \"ARKODE3\"]\nwp = WorkPrecisionSet(prob,abstols,reltols,setups;\n                      names=names,save_everystep=false,appxsol=test_sol,maxiters=Int(1e5),seconds=5)\nplot(wp)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "setups = [Dict(:alg=>Rosenbrock23()),\n          Dict(:alg=>TRBDF2()),\n          Dict(:alg=>ImplicitEulerExtrapolation()),\n          #Dict(:alg=>ImplicitDeuflhardExtrapolation()), # Diverges\n          #Dict(:alg=>ImplicitHairerWannerExtrapolation()), # Diverges\n          Dict(:alg=>ABDF2()),\n          #Dict(:alg=>QNDF()), # ???\n          #Dict(:alg=>Exprb43()), # Diverges\n          Dict(:alg=>Exprb32()),\n]\nwp = WorkPrecisionSet(prob,abstols,reltols,setups;\n                      save_everystep=false,appxsol=test_sol,maxiters=Int(1e5),numruns=10)\nplot(wp)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that `KenCarp4` is the same overarching algorithm as `ARKODE` here (with major differences to stage predictors and adaptivity though). In this case, `KenCarp4` is more robust and more efficient than `ARKODE`. `CVODE_BDF` does quite well here, which is unusual for it on small equations. You can see that the low-order Rosenbrock methods `Rosenbrock23` and `Rodas3` dominate this test.\n\n#### Timeseries error\n\nNow we measure the average error of the timeseries."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "abstols = 1.0 ./ 10.0 .^ (4:7)\nreltols = 1.0 ./ 10.0 .^ (1:4)\n\nsetups = [Dict(:alg=>Rosenbrock23()),\n          Dict(:alg=>CVODE_BDF()),\n          Dict(:alg=>TRBDF2()),\n          Dict(:alg=>ddebdf()),\n          Dict(:alg=>rodas()),\n          Dict(:alg=>lsoda()),\n          Dict(:alg=>radau())]\nwp = WorkPrecisionSet(prob,abstols,reltols,setups;\n                      error_estimator=:l2,appxsol=test_sol,maxiters=Int(1e5),seconds=5)\nplot(wp)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "setups = [Dict(:alg=>Rosenbrock23()),\n          Dict(:alg=>Rodas3()),\n          Dict(:alg=>TRBDF2()),\n          Dict(:alg=>rodas()),\n          Dict(:alg=>lsoda()),\n          Dict(:alg=>radau()),\n          Dict(:alg=>RadauIIA5()),\n          Dict(:alg=>ROS34PW1a()),\n          ]\ngr()\nwp = WorkPrecisionSet(prob,abstols,reltols,setups;error_estimator=:l2,\n                      save_everystep=false,appxsol=test_sol,maxiters=Int(1e5),numruns=10)\nplot(wp)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "setups = [Dict(:alg=>Rosenbrock23(),:dense=>false),\n          Dict(:alg=>Kvaerno3(),:dense=>false),\n          Dict(:alg=>KenCarp4(),:dense=>false),\n          Dict(:alg=>TRBDF2(),:dense=>false),\n          Dict(:alg=>KenCarp3(),:dense=>false),\n          Dict(:alg=>SDIRK2(),:dense=>false),\n          Dict(:alg=>radau())]\nnames = [\"Rosenbrock23\" \"Kvaerno3\" \"KenCarp4\" \"TRBDF2\" \"KenCarp3\" \"SDIRK2\" \"radau\"]\nwp = WorkPrecisionSet(prob,abstols,reltols,setups;\n                      names=names,appxsol=test_sol,maxiters=Int(1e5),error_estimator=:l2,seconds=5)\nplot(wp)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "setups = [Dict(:alg=>Rosenbrock23()),\n          Dict(:alg=>TRBDF2()),\n          Dict(:alg=>ImplicitEulerExtrapolation()),\n          #Dict(:alg=>ImplicitDeuflhardExtrapolation()), # Diverges\n          #Dict(:alg=>ImplicitHairerWannerExtrapolation()), # Diverges\n          Dict(:alg=>ABDF2()),\n          #Dict(:alg=>QNDF()), # ???\n          #Dict(:alg=>Exprb43()), # Diverges\n          Dict(:alg=>Exprb32()),\n]\nwp = WorkPrecisionSet(prob,abstols,reltols,setups;error_estimator=:l2,\n                      save_everystep=false,appxsol=test_sol,maxiters=Int(1e5),numruns=10)\nplot(wp)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Higher accuracy tests\n\nNow we transition to higher accracy tests. In this domain higher order methods are stable and much more efficient."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "abstols = 1.0 ./ 10.0 .^ (7:11)\nreltols = 1.0 ./ 10.0 .^ (4:8)\nsetups = [Dict(:alg=>Rodas3()),\n          Dict(:alg=>GRK4A()),\n          Dict(:alg=>Rodas4P()),\n          Dict(:alg=>CVODE_BDF()),\n          Dict(:alg=>Rodas4()),\n          Dict(:alg=>rodas()),\n          Dict(:alg=>radau()),\n          Dict(:alg=>lsoda()),\n          Dict(:alg=>RadauIIA5()),\n          Dict(:alg=>Rodas5())]\nwp = WorkPrecisionSet(prob,abstols,reltols,setups;\n                      save_everystep=false,appxsol=test_sol,maxiters=Int(1e6),seconds=5)\nplot(wp)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "abstols = 1.0 ./ 10.0 .^ (7:11)\nreltols = 1.0 ./ 10.0 .^ (4:8)\nsetups = [Dict(:alg=>Rodas3()),\n          Dict(:alg=>Kvaerno4()),\n          Dict(:alg=>Kvaerno5()),\n          Dict(:alg=>CVODE_BDF()),\n          Dict(:alg=>KenCarp4()),\n          Dict(:alg=>KenCarp5()),\n          Dict(:alg=>ARKODE()),\n          Dict(:alg=>Rodas4()),\n          Dict(:alg=>radau()),\n          Dict(:alg=>Rodas5())]\nnames = [\"Rodas3\" \"Kvaerno4\" \"Kvaerno5\" \"CVODE_BDF\" \"KenCarp4\" \"KenCarp5\" \"ARKODE\" \"Rodas4\" \"radau\" \"Rodas5\"]\nwp = WorkPrecisionSet(prob,abstols,reltols,setups;\n                      names=names,save_everystep=false,appxsol=test_sol,maxiters=Int(1e6),seconds=5)\nplot(wp)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "setups = [Dict(:alg=>Rodas3()),\n          Dict(:alg=>CVODE_BDF()),\n          Dict(:alg=>Rodas4()),\n          Dict(:alg=>radau()),\n          Dict(:alg=>Rodas5())]\nwp = WorkPrecisionSet(prob,abstols,reltols,setups;\n                      save_everystep=false,appxsol=test_sol,maxiters=Int(1e6),seconds=5)\nplot(wp)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Timeseries Errors"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "abstols = 1.0 ./ 10.0 .^ (7:11)\nreltols = 1.0 ./ 10.0 .^ (4:8)\nsetups = [Dict(:alg=>Rodas3()),\n          Dict(:alg=>GRK4A()),\n          Dict(:alg=>Rodas4P()),\n          Dict(:alg=>CVODE_BDF()),\n          Dict(:alg=>Rodas4()),\n          Dict(:alg=>rodas()),\n          Dict(:alg=>radau()),\n          Dict(:alg=>lsoda()),\n          Dict(:alg=>RadauIIA5()),\n          Dict(:alg=>Rodas5())]\nwp = WorkPrecisionSet(prob,abstols,reltols,setups;error_estimate=:l2,\n                      save_everystep=false,appxsol=test_sol,maxiters=Int(1e6),seconds=5)\nplot(wp)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "setups = [Dict(:alg=>Rodas3()),\n          Dict(:alg=>Kvaerno4()),\n          Dict(:alg=>Kvaerno5()),\n          Dict(:alg=>CVODE_BDF()),\n          Dict(:alg=>KenCarp4()),\n          Dict(:alg=>KenCarp5()),\n          Dict(:alg=>Rodas4()),\n          Dict(:alg=>radau()),\n          Dict(:alg=>Rodas5())]\nnames = [\"Rodas3\" \"Kvaerno4\" \"Kvaerno5\" \"CVODE_BDF\" \"KenCarp4\" \"KenCarp5\" \"Rodas4\" \"radau\" \"Rodas5\"]\nwp = WorkPrecisionSet(prob,abstols,reltols,setups;\n                      names=names,appxsol=test_sol,maxiters=Int(1e6),error_estimate=:l2,seconds=5)\nplot(wp)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "setups = [Dict(:alg=>CVODE_BDF()),\n          Dict(:alg=>Rodas4()),\n          Dict(:alg=>radau()),\n          Dict(:alg=>Rodas5())]\nwp = WorkPrecisionSet(prob,abstols,reltols,setups;\n                      appxsol=test_sol,maxiters=Int(1e6),error_estimate=:l2,seconds=5)\nplot(wp)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The timeseries test is a little odd here because of the high peaks in the VanDerPol oscillator. At a certain accuracy, the steps try to resolve those peaks and so the error becomes higher.\n\nWhile the higher order order Julia-based Rodas methods (`Rodas4` and `Rodas4P`) Rosenbrock methods are not viable at higher tolerances, they dominate for a large portion of this benchmark. When the tolerance gets low enough, `radau` adaptive high order (up to order 13) takes the lead.\n\n### Conclusion\n\n`Rosenbrock23` and `Rodas3` do well when tolerances are higher. In most standard tolerances, `Rodas4` and `Rodas4P` do extremely well. Only when the tolerances get very low does `radau` do well. The Julia Rosenbrock methods vastly outperform their Fortran counterparts. `CVODE_BDF` is a top performer in the final timepoint errors with low accuracy, but take that with a grain of salt because the problem is periodic which means it's getting the spikes wrong but the low parts correct. `ARKODE` does poorly in these tests. `lsoda` does quite well in both low and high accuracy domains, but is never the top."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using DiffEqBenchmarks\nDiffEqBenchmarks.bench_footer(WEAVE_ARGS[:folder],WEAVE_ARGS[:file])"
      ],
      "metadata": {},
      "execution_count": null
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.4.2"
    },
    "kernelspec": {
      "name": "julia-1.4",
      "display_name": "Julia 1.4.2",
      "language": "julia"
    }
  },
  "nbformat": 4
}
